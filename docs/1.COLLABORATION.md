# COLLABORATION GUIDE: n8n Docker Stack Project

## Overview

A complete Docker Compose setup for running n8n (workflow automation platform) with PostgreSQL database, automatic workflow import, and Ollama AI integration. This project provides a production-ready n8n instance with persistent data storage, pre-configured workflows, and seamless container orchestration.

---

## Project Structure & Responsibilities

Complete Docker-based n8n automation platform with PostgreSQL database and workflow management.

```
/ (root)
├── README.md - Project overview and quick start guide
├── LICENSE - Project license information
├── CHANGELOG.md - Project change history
├── docs/ - Project documentation and design specifications
│   ├── 1.COLLABORATION.md - This collaboration guide
│   └── designs/ - Architecture and use case documentation
│       ├── architecture.md - System architecture with component diagrams
│       ├── use_cases.md - Detailed use cases with state diagrams
│       └── setup_guide.md - Comprehensive setup and configuration guide
└── src/ - Main project source code and configuration
    ├── monitoring/ - Comprehensive monitoring stack with Prometheus, Grafana, and AlertManager
    │   ├── docker-compose.monitoring.yml - Multi-service monitoring orchestration (Prometheus, Grafana, AlertManager, exporters)
    │   ├── README.md - Complete monitoring setup and usage guide
    │   ├── start-monitoring.sh - Automated monitoring stack startup script
    │   ├── test-monitoring.sh - Comprehensive monitoring functional tests
    │   ├── verify-integration.sh - Integration verification and validation script
    │   ├── prometheus/ - Prometheus configuration and alert rules
    │   │   ├── prometheus.yml - Metrics collection configuration and scraping targets
    │   │   └── alert_rules.yml - Alert rules for service health and performance monitoring
    │   ├── grafana/ - Grafana dashboards and provisioning configuration
    │   │   ├── dashboards/ - Pre-configured monitoring dashboards (n8n-overview.json, system-overview.json)
    │   │   └── provisioning/ - Automatic dashboard and datasource provisioning
    │   │       ├── dashboards/dashboards.yml - Dashboard provisioning configuration
    │   │       └── datasources/prometheus.yml - Prometheus datasource configuration
    │   └── alertmanager/ - AlertManager configuration for alert routing and notifications
    │       └── alertmanager.yml - Alert routing rules and notification channels
    ├── security/ - Security hardening components with SSL, authentication, and intrusion prevention
    │   ├── docker-compose.security.yml - Security-enhanced stack with reverse proxy, SSL, and network isolation
    │   ├── README.md - Complete security setup and configuration guide
    │   ├── setup-security.sh - Automated security initialization and configuration script
    │   ├── nginx/ - Nginx reverse proxy with SSL termination and security headers
    │   │   ├── nginx.conf - Main nginx configuration with SSL, rate limiting, and security headers
    │   │   ├── default.conf - Default site configuration with WebSocket support for n8n
    │   │   ├── nginx.conf.main - Main nginx server configuration
    │   │   ├── generate-ssl.sh - Self-signed SSL certificate generation script
    │   │   └── ssl/ - SSL certificates directory
    │   │       ├── nginx.crt - SSL certificate for HTTPS (generated)
    │   │       └── nginx.key - SSL private key (generated)
    │   ├── fail2ban/ - Intrusion prevention and IP blocking
    │   │   ├── jail.local - Fail2ban jail configuration for nginx protection
    │   │   ├── filter-nginx-auth.conf - Custom filter for nginx authentication failures
    │   │   └── filter-nginx-limit-req.conf - Custom filter for nginx rate limit violations
    │   └── secrets/ - Secure credential and encryption key management
    │       ├── generate-secrets.sh - Automated secure password and key generation script
    │       ├── docker-secrets.yml - Docker secrets configuration for credential management
    │       ├── postgres_user.txt - PostgreSQL username (generated)
    │       ├── postgres_password.txt - PostgreSQL secure password (generated)
    │       ├── postgres_db.txt - PostgreSQL database name (generated)
    │       ├── n8n_basic_auth_user.txt - n8n basic authentication username (generated)
    │       ├── n8n_basic_auth_password.txt - n8n basic authentication password (generated)
    │       ├── n8n_encryption_key.txt - n8n data encryption key (generated)
    │       ├── grafana_admin_user.txt - Grafana admin username (generated)
    │       └── grafana_admin_password.txt - Grafana admin password (generated)
    ├── backup-restore/ - Automated backup and disaster recovery system
    │   ├── automated-backups/ - Comprehensive backup automation with integrity verification
    │   │   ├── backup.sh - Main automated backup script for database, data, and configurations
    │   │   └── backup.sh.bak - Backup script backup for version control
    │   └── restore-scripts/ - Complete restore procedures with selective recovery options
    │       └── restore.sh - Main restore script with database, data, and configuration recovery
    └── n8n/ - n8n Docker stack implementation
        └── src/ - Core n8n Docker configuration and files
            ├── .n8n.env - n8n service configuration (database, auth, execution settings) [create from .n8n.env.template]
            ├── .n8n.env.template - Template for n8n environment configuration
            ├── .postgresql.env - PostgreSQL database credentials [create from .postgresql.env.template]
            ├── .postgresql.env.template - Template for PostgreSQL environment configuration
            ├── docker-compose.n8n.yml - Multi-service orchestration (n8n, PostgreSQL, Ollama, workflow-importer)
            ├── Dockerfile - Custom n8n image with jq and zip utilities
            ├── scripts/
            │   └── import-workflows.sh - Automated workflow import script
            ├── workflows/ - Pre-configured n8n workflow JSON files (auto-imported on startup)
            │   ├── content.md - Documentation for workflow purposes
            │   ├── purpose.md - Workflow collection overview
            │   ├── delete_archived_workflows.json - Cleanup automation
            │   ├── github_repo_workflows_sync.json - GitHub repository synchronization
            │   ├── github_workflows_backup.json - Backup automation for GitHub workflows
            │   ├── gtree_build_context.json - Context building for project trees
            │   ├── gtree_creator.json - Project tree generation workflow
            │   ├── gtree_get.json - Project tree retrieval workflow
            │   ├── test_copy.json - Testing and copying utilities
            │   ├── zip_make.json - Archive creation workflow
            │   └── zip_send.json - Archive distribution workflow
            └── localfiles/ - Local file storage mounted to n8n container
                ├── purpose.md - Documentation for local file usage
                ├── someserver/ - Example server application with FastAPI
                │   ├── Dockerfile - Python FastAPI server container
                │   ├── main.py - FastAPI application entry point
                │   └── requirements.txt - Python dependencies
                ├── someserver.tar.gz - Compressed server archive
                └── someserver.zip - Server archive in ZIP format
```

---

## Key Technologies

- **n8n**: Open-source workflow automation platform for connecting apps and automating tasks
- **Docker & Docker Compose**: Containerization and multi-service orchestration for consistent deployment
- **PostgreSQL**: Relational database for persistent storage of n8n workflows, credentials, and execution data
- **Ollama**: Local AI model serving platform integrated for AI-powered workflow capabilities
- **Prometheus**: Metrics collection and time-series database for monitoring and alerting
- **Grafana**: Visualization dashboards and alerting interface for monitoring data
- **AlertManager**: Alert routing and notification management for operational monitoring
- **Alpine Linux**: Lightweight base OS for custom Docker image with jq and zip utilities
- **Bash Scripting**: Automated workflow import and management scripts
- **JSON**: Workflow definition format for n8n automation configurations
- **Nginx**: Reverse proxy with SSL termination, security headers, and rate limiting
- **Fail2ban**: Intrusion prevention system for detecting and blocking malicious access attempts
- **OpenSSL**: SSL/TLS certificate generation and cryptographic operations
- **FastAPI**: Python web framework for example server applications in localfiles

---

## Project Details: File & Directory Responsibilities

### Container Services (Docker Compose)

**n8n Stack Services**
- `postgres`: PostgreSQL 15 database service with health checks and persistent storage
- `workflow-importer`: One-time service for importing JSON workflows on startup
- `n8n`: Main n8n automation platform service with web interface and API
- `ollama`: AI model serving platform for LLM integration in workflows

**Monitoring Stack Services**
- `prometheus`: Metrics collection and time-series database with 30-day retention
- `grafana`: Visualization dashboards and alerting interface (admin/admin_password)
- `alertmanager`: Alert routing and notification management with webhook integration
- `node-exporter`: System metrics collection (CPU, memory, disk, network)
- `cadvisor`: Docker container metrics collection and monitoring
- `postgres-exporter`: PostgreSQL database metrics collection and health monitoring

**Security Stack Services**
- `nginx`: Reverse proxy with SSL termination, security headers, and rate limiting
- `fail2ban`: Intrusion prevention system for detecting and blocking malicious IPs
- `postgres`: Secure PostgreSQL with Docker secrets for credential management
- `n8n`: Security-enhanced n8n with network isolation and encrypted communication

### Configuration Management

**Docker Configuration**
- `src/n8n/src/docker-compose.n8n.yml`: Multi-service orchestration with health checks and service dependencies
- `src/n8n/src/Dockerfile`: Custom n8n image with jq and zip utilities for workflow processing
- `src/monitoring/docker-compose.monitoring.yml`: Complete monitoring stack orchestration with Prometheus, Grafana, AlertManager, and exporters
- `src/security/docker-compose.security.yml`: Security-enhanced stack with SSL, reverse proxy, network isolation, and secrets management

**Environment Files**
- `src/n8n/src/.n8n.env`: n8n service configuration (database connection, authentication, execution settings)
- `src/n8n/src/.postgresql.env`: PostgreSQL database credentials and connection parameters

**Security Configuration**
- `src/security/nginx/nginx.conf`: Main nginx configuration with SSL, security headers, and rate limiting
- `src/security/fail2ban/jail.local`: Fail2ban jail configuration for nginx protection
- `src/security/secrets/`: Secure credential management with Docker secrets

### Workflow Management

**Workflow Structure**
- `src/n8n/src/workflows/`: JSON workflow definitions automatically imported on container startup
- `src/n8n/src/scripts/import-workflows.sh`: Intelligent workflow import script with duplicate detection
- Automatic import process runs before n8n service starts to ensure workflows are available immediately

### Data & Storage

**Volume Management**
- `src/n8n/src/localfiles/`: Host directory mounted to `/files` in n8n container for file operations
- `n8n_data`: Docker volume for persistent n8n application data
- `postgres_data`: Docker volume for PostgreSQL database storage
- `ollama-data`: Docker volume for Ollama AI model storage

**Monitoring Data Storage**
- `prometheus_data`: Docker volume for Prometheus metrics storage (30-day retention)
- `grafana_data`: Docker volume for Grafana dashboards, settings, and user data
- `alertmanager_data`: Docker volume for AlertManager configuration and alert state

### Backup & Disaster Recovery

**Backup System**
- `src/backup-restore/automated-backups/backup.sh`: Comprehensive backup script for database, data, and configurations
- `src/backup-restore/restore-scripts/restore.sh`: Complete restore procedures with selective recovery options
- Automated backup verification and integrity checking
- Configurable retention policies with automated cleanup

**Security & Hardening**
- `src/security/setup-security.sh`: Automated security initialization and configuration script
- `src/security/nginx/generate-ssl.sh`: Self-signed SSL certificate generation for development/testing
- `src/security/secrets/generate-secrets.sh`: Secure password and encryption key generation

## Tools

A list of tools required for this project to be run and debugged.

### Tool: Docker & Docker Compose

**Requirements**
- Docker Engine 20.10+ installed and running
- Docker Compose V2 (included with Docker Desktop)
- Minimum 4GB RAM available for containers
- Port 5678 available for n8n web interface
- Port 11434 available for Ollama AI service

**Configurations Docker**
- `src/n8n/src/docker-compose.yml`: Multi-service orchestration with health checks and dependencies
- `src/n8n/src/Dockerfile`: Custom n8n image with jq and zip utilities for workflow processing

### Tool: n8n Workflow Automation

**Requirements**
- PostgreSQL database connection for persistent storage
- Basic authentication credentials configured
- Workflow JSON files in proper n8n export format
- Community packages enabled for extended functionality

**Configurations n8n**
- `src/n8n/src/.n8n.env`: Complete n8n service configuration including database, auth, and execution settings
- `src/n8n/src/workflows/*.json`: Pre-configured workflow definitions for automatic import
- `src/n8n/src/scripts/import-workflows.sh`: Automated workflow import with duplicate detection

### Tool: PostgreSQL Database

**Requirements**
- PostgreSQL 15 compatible environment
- Database initialization with n8n schema
- Persistent volume storage for data retention
- Health check configuration for service dependencies

**Configurations PostgreSQL**
- `src/n8n/src/.postgresql.env`: Database credentials and connection parameters
- Health check configuration in `src/n8n/src/docker-compose.yml` for service readiness

### Tool: Ollama AI Platform

**Requirements**
- 4GB memory limit for AI model operations
- Persistent storage for downloaded AI models
- Network connectivity for model downloads
- Compatible with llama3.2:3b model

**Configurations Ollama**
- Service configuration in `src/n8n/src/docker-compose.yml` with memory limits
- Volume mount for persistent model storage
- Automatic model download on container startup

### Tool: Monitoring Stack (Prometheus & Grafana)

**Requirements**
- Docker Compose V2 for monitoring stack deployment
- Network connectivity to n8n stack for metrics collection
- Minimum 2GB additional RAM for monitoring services
- Ports 3000 (Grafana), 9090 (Prometheus), 9093 (AlertManager) available
- Basic understanding of monitoring and alerting concepts

**Configurations Monitoring Stack**
- `src/monitoring/docker-compose.monitoring.yml`: Complete monitoring services orchestration with health checks
- `src/monitoring/prometheus/prometheus.yml`: Metrics collection configuration with scraping targets for n8n, PostgreSQL, system, and container metrics
- `src/monitoring/prometheus/alert_rules.yml`: Alert rules for service health, resource usage, and performance monitoring
- `src/monitoring/grafana/provisioning/`: Automatic dashboard and datasource provisioning configuration
- `src/monitoring/alertmanager/alertmanager.yml`: Alert routing rules and notification channels including webhook integration

### Tool: Security Hardening & SSL

**Requirements**
- OpenSSL for certificate generation and cryptographic operations
- Docker secrets support for secure credential management
- Network isolation capabilities for container security
- Basic understanding of SSL/TLS and security hardening principles

**Configurations Security**
- `src/security/docker-compose.security.yml`: Security-enhanced stack with SSL, reverse proxy, and network isolation
- `src/security/nginx/nginx.conf`: Main nginx configuration with SSL, security headers, and rate limiting
- `src/security/fail2ban/jail.local`: Fail2ban jail configuration for intrusion prevention
- `src/security/secrets/`: Secure credential and encryption key management directory

### Tool: Backup & Disaster Recovery

**Requirements**
- Sufficient disk space for backup storage (default: `/tmp/n8n_backups`)
- Cron or systemd for automated backup scheduling
- Docker volume access for data backup and restore operations
- Understanding of backup retention and disaster recovery procedures

**Configurations Backup System**
- `src/backup-restore/automated-backups/backup.sh`: Main backup script with integrity verification
- `src/backup-restore/restore-scripts/restore.sh`: Complete restore procedures with selective recovery
- Backup retention configuration (default: 30 days)
- Backup verification and integrity checking

### Tool: Testing and Validation Scripts

**Requirements**
- Bash shell environment
- `curl`, `jq`, and `docker` command-line utilities
- Access to Docker daemon and container networks
- Network connectivity to monitoring service endpoints

**Configurations Testing Scripts**
- `src/monitoring/test-monitoring.sh`: Comprehensive monitoring functionality testing with health checks
- `src/monitoring/verify-integration.sh`: Complete integration verification against project plan  
- `src/monitoring/start-monitoring.sh`: Automated monitoring startup with health validation
- Test endpoints: Prometheus (:9090), Grafana (:3000), AlertManager (:9093), exporters

## Setup & Development

### Prerequisites

- Docker Engine 20.10+ and Docker Compose V2
- Git for repository cloning
- 6GB+ available RAM for containers (4GB for n8n stack + 2GB for monitoring)
- Ports 5678 (n8n), 11434 (Ollama), 3000 (Grafana), 9090 (Prometheus), 9093 (AlertManager), 9100 (Node Exporter), 8080 (cAdvisor), 9187 (PostgreSQL Exporter) available
- Additional ports for security stack: 80 (HTTP), 443 (HTTPS) when using security hardening
- Basic understanding of n8n workflow automation and monitoring concepts
- `curl`, `jq`, `openssl`, and `netstat` utilities for debugging and testing
- For security features: Understanding of SSL/TLS, reverse proxies, and intrusion prevention

### Install Dependencies

```sh
# Clone the repository
git clone <your-repo-url>
cd n8n_docker_stack

# Navigate to n8n source directory
cd src/n8n/src

# Create required environment files from templates
cp .n8n.env.template .n8n.env
cp .postgresql.env.template .postgresql.env

# ⚠️ IMPORTANT: Edit both files to customize credentials and settings
# See docs/designs/setup_guide.md for detailed configuration instructions

# Start the complete stack
docker-compose -f docker-compose.n8n.yml up -d

# Verify services are running
docker-compose -f docker-compose.n8n.yml ps

# Check workflow import logs
docker-compose -f docker-compose.n8n.yml logs workflow-importer

# Access n8n web interface
open http://localhost:5678

# Optional: Start monitoring stack for observability
cd ../../monitoring
docker-compose -f docker-compose.monitoring.yml up -d

# Verify monitoring stack functionality
bash test-monitoring.sh

# Access monitoring dashboards
open http://localhost:3000  # Grafana (admin/admin_password)
open http://localhost:9090  # Prometheus

# Optional: Setup security hardening with SSL and intrusion prevention
cd ../../security
bash setup-security.sh

# Start security-enhanced stack (replaces basic n8n stack)
docker-compose -f docker-compose.security.yml up -d

# Access n8n securely with HTTPS
open https://localhost  # n8n via secure nginx reverse proxy

# Optional: Setup automated backups
cd ../backup-restore/automated-backups
bash backup.sh  # Manual backup

# Schedule automated backups (example for cron)
echo "0 2 * * * $(pwd)/backup.sh" | crontab -
```


## Build & Deployment

### Build

Build custom n8n Docker image with additional utilities and deploy the complete stack:

```sh
# Navigate to n8n source directory
cd src/n8n/src

# Build custom n8n image with jq and zip utilities
docker-compose -f docker-compose.n8n.yml build

# Start all services with automatic workflow import
docker-compose -f docker-compose.n8n.yml up -d

# Rebuild and restart specific service
docker-compose -f docker-compose.n8n.yml up -d --build n8n

# Force rebuild workflow importer
docker-compose -f docker-compose.n8n.yml up workflow-importer --force-recreate

# Build security-enhanced stack with custom nginx configuration
cd ../../security
docker-compose -f docker-compose.security.yml build

# Build monitoring stack with custom configurations
cd ../monitoring
docker-compose -f docker-compose.monitoring.yml build
```

### Deploy

Deploy the n8n automation platform for production or development environments:

```sh
# Development deployment (basic stack)
cd src/n8n/src
docker-compose -f docker-compose.n8n.yml up -d

# Production deployment with security hardening
cd ../../security
bash setup-security.sh  # Initialize security components
docker-compose -f docker-compose.security.yml up -d

# Deploy monitoring stack
cd ../monitoring
docker-compose -f docker-compose.monitoring.yml up -d

# Verify monitoring deployment
bash start-monitoring.sh

# Update to latest n8n version
cd ../n8n/src
docker-compose -f docker-compose.n8n.yml pull
docker-compose -f docker-compose.n8n.yml up -d

# Scale specific services (if needed)
docker-compose -f docker-compose.n8n.yml up -d --scale n8n=1

# Deploy all stacks together (complete production setup)
cd ../../security
bash setup-security.sh
docker-compose -f docker-compose.security.yml up -d
cd ../monitoring
docker-compose -f docker-compose.monitoring.yml up -d
bash verify-integration.sh
```
```

## Debugging

Provides a set of strategies for debugging the n8n Docker stack and workflow automation.

**Debugging Strategy: Container Service Issues**

```sh
# Navigate to n8n source directory
cd src/n8n/src

# Check service status and health
docker-compose -f docker-compose.n8n.yml ps
docker-compose -f docker-compose.n8n.yml logs -f n8n
docker-compose -f docker-compose.n8n.yml logs -f postgres
docker-compose -f docker-compose.n8n.yml logs workflow-importer

# Restart specific services
docker-compose -f docker-compose.n8n.yml restart n8n
docker-compose -f docker-compose.n8n.yml restart postgres

# Rebuild and restart with fresh containers
docker-compose -f docker-compose.n8n.yml down
docker-compose -f docker-compose.n8n.yml up -d --build

# Check database connectivity
docker-compose -f docker-compose.n8n.yml exec postgres psql -U n8n -d n8n -c "\dt"
```

**Debugging Strategy: Workflow Import Issues**

```sh
# Navigate to n8n source directory
cd src/n8n/src

# Check workflow import logs
docker-compose -f docker-compose.n8n.yml logs workflow-importer

# Manually trigger workflow import
docker-compose -f docker-compose.n8n.yml up workflow-importer --force-recreate

# Validate workflow JSON files
for file in workflows/*.json; do echo "Checking $file:"; jq empty "$file" && echo "✅ Valid" || echo "❌ Invalid"; done

# Test n8n CLI commands inside container
docker-compose -f docker-compose.n8n.yml exec n8n n8n list:workflow
docker-compose -f docker-compose.n8n.yml exec n8n n8n import:workflow --input=/workflows/your-workflow.json
```

**Debugging Strategy: Network and Port Issues**

```sh
# Check port availability
netstat -an | grep 5678
netstat -an | grep 11434

# Test n8n web interface connectivity
curl -I http://localhost:5678

# Check container network connectivity
docker-compose -f docker-compose.n8n.yml exec n8n ping postgres
docker-compose -f docker-compose.n8n.yml exec n8n ping ollama

# Verify environment variables
docker-compose -f docker-compose.n8n.yml exec n8n env | grep N8N
docker-compose -f docker-compose.n8n.yml exec postgres env | grep POSTGRES
**Debugging Strategy: Monitoring Stack Testing and Validation**

```sh
# Navigate to monitoring directory
cd src/monitoring

# Run comprehensive monitoring tests
bash test-monitoring.sh

# Verify complete integration
bash verify-integration.sh

# Start monitoring stack with automated checks
bash start-monitoring.sh

# Check individual service health
curl http://localhost:9090/-/healthy    # Prometheus
curl http://localhost:3000/api/health   # Grafana  
curl http://localhost:9093/-/healthy    # AlertManager

# Test Prometheus targets and metrics
curl http://localhost:9090/api/v1/targets
curl http://localhost:9090/api/v1/query?query=up

# Test Grafana datasources
curl -u admin:admin_password http://localhost:3000/api/datasources

# Check monitoring service logs
docker-compose -f docker-compose.monitoring.yml logs -f grafana
docker-compose -f docker-compose.monitoring.yml logs alertmanager

# Restart monitoring services
docker-compose -f docker-compose.monitoring.yml restart

# Check Prometheus targets and configuration
curl http://localhost:9090/api/v1/targets
curl http://localhost:9090/api/v1/status/config
```
```
```

**DEBUGGING: GOTCHAs AND RECOVERY**

A list of tips and tricks for detailing with debugging gotchas.
NOTE: !! do not change this.

- The ERROR: "Unexpected eof" (end of file) | Can typically mean there is a missing or extra bracket/parenthesis. However, can be some times caused by mis-aligned quote types (i.e. opening quote: \' while closing quote '") or additionally by missing tags. Please rewrite the given file to fix the error even if it looks correct. Mistakes happen.
- ERROR: "command n8n not found" | Fixed by using official Docker registry image `docker.n8n.io/n8nio/n8n` instead of custom commands
- ERROR: Database connection refused | Ensure PostgreSQL health check passes before n8n starts, check `.postgresql.env` credentials
- ERROR: Port already in use | Change port mapping in docker-compose.yml or stop conflicting services
- ERROR: Workflow import failed | Validate JSON syntax with `jq empty workflow.json`, check workflow format compatibility
- ERROR: Permission denied on volumes | Ensure Docker has proper permissions for volume mount directories
- ERROR: Ollama model download timeout | Increase memory limits or download models manually with `docker-compose exec ollama ollama pull llama3.2:3b`
- ERROR: Grafana login issues | Use default credentials admin/admin_password for local instance, not Grafana Cloud credentials
- ERROR: Prometheus targets down | Check service connectivity and network configuration, ensure n8n stack is running before monitoring
- ERROR: Monitoring services port conflicts | Change port mappings in docker-compose.monitoring.yml or stop conflicting services
- ERROR: "Missing dependencies: curl jq docker openssl" | Install required dependencies: `brew install curl jq openssl` on macOS or `apt-get install curl jq openssl` on Ubuntu
- ERROR: Monitoring container names not found | Ensure monitoring stack is started with correct compose file: `docker-compose -f docker-compose.monitoring.yml up -d`
- ERROR: Network "monitoring" not found | Create monitoring network manually: `docker network create monitoring`
- ERROR: Metrics endpoint not responding | Check if services expose metrics on correct ports and endpoints (/metrics)
- ERROR: Prometheus scrape targets down | Verify network connectivity between containers and check firewall rules
- ERROR: SSL certificate errors | Regenerate certificates with `cd src/security/nginx && bash generate-ssl.sh`
- ERROR: Nginx configuration test failed | Validate nginx syntax with `docker run --rm -v "$(pwd)/nginx.conf:/etc/nginx/conf.d/default.conf:ro" nginx:alpine nginx -t`
- ERROR: Fail2ban service not starting | Check fail2ban configuration and ensure proper permissions on jail files
- ERROR: HTTPS access denied | Verify nginx reverse proxy configuration and SSL certificate installation
- ERROR: Backup script permission denied | Make backup scripts executable with `chmod +x src/backup-restore/automated-backups/backup.sh`
- ERROR: Restore operation failed | Ensure target containers are stopped and backup files exist with correct timestamps
- ERROR: Secret files not found | Run security setup script: `cd src/security && bash setup-security.sh`
- ERROR: Docker secrets not available | Ensure using `docker-compose.security.yml` which includes secrets configuration

## Git Commit Best 

The require git commit policies to follow.
NOTE: !! do not change this.

**Git Commands**

- Use the `git status` command to get a clear view of what you are updating.
- Add and commit your changes with a helpful message using `git add -A && git commit -m '[HELPFUL COMMIT MESSAGE HERE]'`

**Basic Rules**
- Git commits should be a wrapper for related changes. For example, fixing two different bugs should produce two separate commits. 
- Commit Often to keep your commits small to enable better reporting on changes and git history management.
- Don't Commit Half-Done Work, only commit code when a logical component is completed. Split a feature's implementation into logical chunks that can be completed quickly so that you can commit often.
- Test Your Code Before You Commit. Follow the Debugging Strategies.
Resist the temptation to commit something that you «think» is completed. Test it thoroughly by making sure the code builds.
- Write clear and Good Commit Messages and keep [.docs/CHANGELOG.md] is up to date. Begin your message with a short summary of your changes (up to 50 characters as a guideline). Separate it from the following body by including a blank line. The body of your message should provide detailed answers to the following questions: – What was the motivation for the change? – How does it differ from the previous implementation? Use the imperative, present tense («change», not «changed» or «changes») to be consistent with generated messages from commands like git merge.


## Collaboration Tips

A summarization of the Collaboration tips and tricks.
NOTE: !! do not change this.

- Keep container services and configurations separated for clarity.
- Use clear commit messages and PR descriptions.
- Document new workflows, configurations, and scripts in the `docs/` folder.
- Update this guide as the project evolves.
- Test workflow imports locally before committing new JSON files.
- Use environment files (.n8n.env, .postgresql.env) for sensitive configuration instead of hardcoding values.
- Validate JSON workflow files with `jq` before adding to the `src/n8n/src/workflows/` directory.
- Document workflow purposes in the `src/n8n/src/workflows/` directory.
- Always run Docker commands from the appropriate source directory (`src/n8n/src/` for n8n stack, `src/monitoring/` for monitoring stack, `src/security/` for security stack).
- Test monitoring functionality with provided scripts (`test-monitoring.sh`, `verify-integration.sh`) before deploying to production.
- Use monitoring dashboards to understand system performance and identify issues early.
- Configure appropriate alert thresholds based on your operational requirements.
- Run `bash test-monitoring.sh` after any monitoring configuration changes to validate functionality.
- Use `bash start-monitoring.sh` for automated monitoring stack startup with health checks.
- Always verify n8n stack is running before starting monitoring stack for proper integration.
- For security deployments, use `docker-compose.security.yml` instead of basic `docker-compose.n8n.yml` in production.
- Run `bash setup-security.sh` before deploying security-enhanced stack to initialize secrets and SSL certificates.
- Test backup and restore procedures regularly using `backup.sh` and `restore.sh --list` commands.
- Use selective restore options (`--database`, `--n8n-data`, `--configs`) for targeted recovery operations.
- Schedule automated backups with cron for production environments.
- Keep backup retention policies aligned with your disaster recovery requirements.
- Always validate SSL certificates and security configurations before production deployment.

## 🔬📚 Research

Find all the research docs related to this project in the directory [./docs/research/] (if it exists).

NOTE: !! do not change this.

**‼️ Rules**

- ✅ Always provide link or path reference to resources used from this Research. Use Oxford Academic citing style, both inline and as a footnote.
- ✅ Always prefer research notes and documentation provided here over your own knowledge.

**📝 Notes**

A set of notes, as markdown files of research relating to topics relevant to this project can be found in [./docs/research/note-*.md] (if research directory exists). Reference these to inform implementations related to this project.

**🌐 Confluence Page documents**

Contains a list of relevant [./docs/research/confluence_pages.md] researched in this project following the template [./docs/ai/templates/__confluence_pages.md] (if research directory exists).

**🌐 Web link documents**

Contains a list of relevant [./docs/research/web_links.md] researched in this project following the template [./docs/ai/templates/__web_links.md] (if research directory exists).
